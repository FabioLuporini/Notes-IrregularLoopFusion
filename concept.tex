\documentclass[a4paper]{article}
\usepackage{pslatex}
\usepackage{authblk}
\bibliographystyle{plainnat}
\usepackage[left=1.4in, right=1.4in]{geometry}
\setlength{\parskip}{0.5cm}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{soul}
\usepackage[toc,page]{appendix}

\title{Sparse Notes on the Fusability of Non-Affine Loops}
\author{F. Luporini}
\date{}

\makeindex


\begin{document}
\lstset{language=C, breaklines=true}
 
\maketitle
\tableofcontents

\clearpage

\section{Characterization}
This document is an attempt at characterizing the conditions under which a sequence of possibly non-affine loop structures (nests) can be fused into a single loop structure. We focus on a particular class of loops, which is very common in scientific computations, e.g. those based on finite element and finite volume methods. This class is broader than that targeted by the polyhedral model, since it includes forms of non-affine loops that are inherently untreatable through polyhedral analysis. Specifically, our loop chains have some peculiarities:
\begin{itemize}
\item (the scope of) a loop chain is delimited either by the scope of the block in which it is embedded or by the presence of global reductions or by calls to external library functions. Most of the times, in real-world applications, loop chains are ``broken`` by the presence of these sort of implicit synchronization points.
\item each loop structure (nest) in the loop chain is characterized by:
  \begin{enumerate}
  \item an outer loop whose bounds are affine functions of some problem-specific parameters, whereas the body could (but also could not) have arrays accessed through non-affine index functions (e.g. indirection arrays);
  \item any inner, non-perfect loop nest is affine;
  \item as a corollary, only one non-affine loop can be present per loop structure, and this has to be the outermost one (or, equivalently, interchangable with the inner ones);
  \item iterations can be executed in any order (no wave-front computations);
  \item any non-affine index function is static, i.e. it never changes in the scope of the loop chain (e.g. the mesh does not change across the time-stepping loop).
  \end{enumerate}
\item any write/increment\footnote{We recall the distinction between write and increment is that increments are associative operations, and therefore amenable to parallelization in the case of an indirect loop, whereas writes are not} occurs on a dataset associated with the outer loop.
\end{itemize}
Also, the optimizations we have in mind are probably more effective when
\begin{itemize}
\item the non-affine index functions describe a mesh, not a generic graph;
\end{itemize}
An example of such a loop chain is provided in the following listing.

\clearpage

\begin{footnotesize}
\begin{lstlisting}
for t in timesteps:
{
  // loop structure 0, read indirectly, increment indirectly
  for i=0, i<E, i++
    a0 = A[map_a0[i+0]]
    a1 = A[map_a0[i+1]]
    a2 = A[map_a0[i+2]]
    ...
    for j=0, j<18, j++
      tmp[j] = h(a0, a1, ...)
    C[map_c0[i]+0] += tmp[0]
    C[map_c0[i]+1] += tmp[1]
    ...

  // loop structure 1, read indirectly, increment indirectly
  for i=0, i<C, i++
    a0 = A[map_a1[i+0]]
    a1 = A[map_a1[i+1]]
    a2 = A[map_a1[i+2]]
    for j=0, j<9, j++
      tmp[j] = f0(a0, a1, a2, ...)
    C[map_c1[i]+0] += tmp[0]
    C[map_c1[i]+1] += tmp[1]
    C[map_c1[i]+2] += tmp[2]
    ... = ...

  // loop structure 2, read indirectly, increment indirectly
  for i=0, i<C, i++
    a0 = A[map_a1[i+0]]
    a1 = A[map_a1[i+1]]
    a2 = A[map_a1[i+2]]
    for j=0, j<3, j++
      tmp[j] = f1(a0, a1, a2, ...)
    D[map_d[i]+0] += tmp[0]
    D[map_d[i]+1] += tmp[1]
    D[map_d[i]+2] += tmp[2]
          
  // loop structure 3, read directly, increment directly
  for i=0, i<V, i++
    E[i] += D[i]*g(...) + C[i]*...

  ...
}
\end{lstlisting}
\end{footnotesize}

The listing is an example of a loop chain that is typical of some explicit fintie element ``Discontinuous Galerkin'' methods. In particular, we notice that:
\begin{itemize}
\item The first loop nest applies a certain function $h$ over all edges in the mesh (a total of $E$ edges) and increments an indirect dataset $C$.
\item The second loop nest applies a certain function $f0$ over all cells in the mesh (a total of $C$ cells) and increments an indirect dataset $C$.
\item The third loop nest applies a certain function $f1$ over all cells in the mesh (a total of $C$ cells) and increments an indirect dataset $D$.
\item The fourth loop nest iterates over all vertices in the mesh (a total of $V$ vertices) and increments a direct dataset $E$ using values in $C$ and $D$.
\end{itemize}

\section{What's already out there: sparse tiling (or soft fusion)}
The generalized full sparse tiling algorithm can be used to group iterations beloging to different (subsequent) loops in a given chain. Sparse tiling, that in this document can be referred to also as \textit{soft fusion} to distinguish from what we propose in the next section, inspects data dependencies to create atomic tasks, or tiles. Another strategy to achieve exactly the same goal is \textit{overlapped tiling}, which, as far as we know, has never been studied in a general setting (i.e. no ``Generalized Overlapped Tiling'' study has ever been published), although the idea per se cannot obviously be considerated new (redundant computation on the boundaries is something widely used, in many different contexts). 

The aforementioned techniques aim to minimize the cost of indirect memory accesses by trying to maximize (read and write) cache locality. They actually represent the best we can do in generic loop chains. However, there can be circumstances and/or sub-regions of a loop chain that are actually amenable to transformations \textit{stronger} than tiling, namely \textit{real or hard fusion}, in which loop bodies are eventually concatenated. We discuss on the advantages of doing so in the next section. For the moment, we clearly state the fundamental condition under which hard fusion is \textbf{not} doable:
\begin{center}
\textit{Consider two consecutive loops \emph{A} and \emph{B}. Whenever \emph{A} indirectly increments a dataset \emph{d}, and \emph{d} is read (either directly or indirectly) by loop \emph{B}, then it becomes practically unfeasible to hardly fuse the two loops; therefore, in such a case, the only solution for increasing cross-loop locality is to resort to tiling (sparse or overlapped).}
\end{center}


%Two ways for tiling non-affine loops we all know are:
%\begin{itemize}
%\item (full) sparse tiling
%\item overlapped tiling
%\end{itemize}
%In particular, a generalized overlapped tiling strategy for non-affine mesh loop structures has never (too strong?) been implemented or extensively studied.
%\subsection{Open problems}
%\begin{itemize}
%\item Extending these tiling techniques to the MPI level. The MPI parallelization strategy might (let me stress: not necessarily) be orthogonal to the actual tiling strategy.
%\end{itemize}

\section{Hard Fusion}
Consider the loop chain described by the first listing of the document. We want to study to what extent these loops are ``hardly fusible``; that is, if and when the different iteration spaces can be collapsed into one and the bodies can be fused into a single body.

We first notice that it is \textbf{not} true that the iterations of the three iteration spaces (cells, edges, and vertices) cannot be related to each other. There are maps, $map_{c0}$ from edges and $map_{c1}$ from cells, that correlate an iteration in these sets to vertices. In other words, the codomain of these maps is the same. We also notice that all of the indirect reads are from unmodified data sets: for example, array $A$ is never modified in the excerpt of the loop chain. We will release this assumption in the following, which will bring us back to think about the need for tiling techniques in order to mix the iterations of different loops. We now show that in this case, these four loops can be hardly fused.

Let us start with simple case, loop structures 2 and 3. Here:
\begin{itemize}
\item loop structure 2 indirectly increments the dataset $D$, associated with vertices.
\item loop structure 3 directly reads from vertices the dataset $D$. Note that at this point, the dataset $C$ has already been updated.
\end{itemize}
In this case, the key observation is that array $D$ only \textit{acts as a temporary}. Despite the two loops iterate over different iteration sets, there is an affine map $map_{d}$ that implicitly relates iterations from these two sets. This sort of analysis can be performed statically (assuming to avoid any pointer aliasing problems). Conceptually (and just conceptually), loop structure 3 could firstly be turned into a loop over cells:

\begin{footnotesize}
\begin{lstlisting}
for t in timesteps:
{
  ...
          
  // loop structure 2, read indirectly, increment indirectly
  for i=0, i<C, i++
    E[map_d[i]] += D'[map_d[i]]*g(...) + C[i]*...

  ...
}
\end{lstlisting}
\end{footnotesize}

Where $D'$ is the dataset of all of the individual increments performed by the preceding loop. Then, loop structures 2 and 3 could now be fused within a single loop structure, as follows (note the absence of the ``temporary`` $D$):

\begin{footnotesize}
\begin{lstlisting}
for t in timesteps:
{
  ...
          
  // loop structure F23, read indirectly, increment directly
  for i=0, i<C, i++
    a0 = A[map_a1[i+0]]
    a1 = A[map_a1[i+1]]
    a2 = A[map_a1[i+2]]
    for j=0, j<3, j++
      tmp[j] = f1(a0, a1, a2, ...)
    E[map_d[i]+0] += tmp[0]*g(...) + C[i]*...
    E[map_d[i]+1] += tmp[1]*g(...) + C[i]*...
    E[map_d[i]+2] += tmp[2]*g(...) + C[i]*...
}
\end{lstlisting}
\end{footnotesize}

We then go on analyzing loop structure 1 and the newly fused loop structure F23. These loops read indirectly from the same dataset $A$ and write indirectly to datasets $C$ and $E$, respectively. Since sharing happen only on read data, there is \textbf{no} read-after-write dependency between these two loops. Further, they iterate along the same iteration space. So, again, these are trivialy hard fusible, as follows:

\begin{footnotesize}
\begin{lstlisting}
for t in timesteps:
{
  ...
          
  // loop structure F123, read indirectly, increment directly
  for i=0, i<C, i++
    a0 = A[map_a1[i+0]]
    a1 = A[map_a1[i+1]]
    a2 = A[map_a1[i+2]]
    for j=0, j<9, j++
      tmp0[j] = f0(a0, a1, a2, ...)
    for j=0, j<3, j++
      tmp1[j] = f1(a0, a1, a2, ...)
    C[map_c1[i]+0] += tmp0[0]
    C[map_c1[i]+1] += tmp0[1]
    C[map_c1[i]+2] += tmp0[2]
    ...
    E[map_d[i]+0] += tmp1[0]*g(...) + C[i]*...
    E[map_d[i]+1] += tmp1[1]*g(...) + C[i]*...
    E[map_d[i]+2] += tmp1[2]*g(...) + C[i]*...
}
\end{lstlisting}
\end{footnotesize}

Note that hard fusion of non-affine loops open new possibilities for fusing the (affine) loops that live in the bodies (if any). Sometimes, due to application properties, the inner affine (non-perfect) loops share some (i.e. subregions of) iteration spaces. 

The most interesting case concerns fusing loop structures 0 and F123. There is some sharing for what concerns read data; more importantly, the output dataset of these two loop structures is the same, namely $C$. The iteration sets of the two loops are different, although maps ($map_{c0}$ and $map_{c1}$) to the same target dataset are present. Both loops perform increments over the same set. Are these loops hard fusible? And if so, what would be the gain?

The key observation is that same locations in $C$ are going to be updated indirectly by iterations of both loop structures multiple times (recall our initial assumptions: these loops are over meshes, so they span whole iteration spaces). In particular, when a cell and an edge are adjacent, they will increment a same subset of locations in $C$. For example, if a cell is triangular, there will be three edges (i.e. three iterations of loop structure $0$) and one cell (one iteration of loop structure $F123$) incrementing the same subset of locations in $C$, indirectly. When fusing loop structures $0$ and $F123$ the goal can be therefore twofold:
\begin{itemize}
\item increasing read-data locality, since both loops are likely to share some read datasets (e.g. $A$ in this example);
\item as in the previous examples, open new possibilities of classic polyhedral optimization for the bodies of the two fused loops (that, in turn, can be characterized by the presence of some affine loops);
\item \textbf{minimizing the number of indirect increments}.
\end{itemize}
The last point is now our primary goal. To motivate the reader, we anticipate that this particular sequence of loop structures occurs in finite elements in the so called ``assembly`` phase, and the increments to the dataset $C$ can be regarded to as the so called ``insertion in the global matrix`` of the assembly phase.

To achieve this goal, some sort of inspector/executor strategy is required. In particular, the inspector should:
\begin{enumerate}
\item if not available already, create a map between the two iteration spaces so that, for example, given a cell, the adjacent edges can be obtained (or viceversa);
\item select a base loop out of $0$ and $F123$; let's say $F123$, which is more intuitive for the sake of this document. This means that $0$ will eventually be incorporated in $F123$;
\item attach a piece of information, $wasexecuted$, to each iteration of loop $0$. In particular, a bit, initialized to 0 and switched to 1 once the corresponding iteration has been executed, is needed;
\item create a new body for $F123$, in which a cell execution is followed by a conditional execution of the three adjacent edges (i.e. they are executed if not already executed);
\item instead of indirectly incrementing $C$, data is stored temporarily in a ``cell-to-buffer dictionary`` that we name $C2Bcache$;
\item once a cell $c$ and the three adjacent edges got executed, the buffer $C2Bcache[c]$ is stored (indirectly) in memory, and the entry is flushed away.
\end{enumerate}

The executor code for the fused loop structures is shown in the following listing.

%\clearpage

\begin{footnotesize}
\begin{lstlisting}
for t in timesteps:
{ 
  // loop structure F0123, read indirectly, increment directly
  for i=0, i<C, i++
    // read stuff for F123, and prefetch wasexecuted[c2e[i]]
    ...

	// execute body of F123, stored in tmp
	// store in the buffer, as follows:
    C2Bcache[i*k + 0] += tmp[0]
    C2Bcache[i*k + 1] += tmp[1]
    C2Bcache[i*k + 2] += tmp[2]
    // go on executing the adjacent edges, if not already executed
    for j=0, j<3, j++
      if wasexecuted[j]:
        continue
      // read stuff for F0; specifically, this might actually be shared with F123
      // execute body of 0, stored in tmp
      C2Bcache[i*k + 0] += tmp[0]
      C2Bcache[i*k + 1] += tmp[1]
      C2Bcache[i*k + 2] += tmp[2]
      ...
      //set wasexecuted[c2e[i]] to 1 because the edge is now executed
      
    if wasexecuted[0] and wasexecuted[1] and wasexecuted[2]
      C[map_c1[i]+0] += C2Bcache[i*k + 0]
      C[map_c1[i]+1] += C2Bcache[i*k + 1]
      ...
}
\end{lstlisting}
\end{footnotesize}

Note that this process introduces small overhead, including the need for indirectly accessing the $wasexecuted$ array. This array can be however prefetched before the cell execution begins (so there should be enough overlap before it is actually used), and it has to be set to 1 once the corresponding edge is executed; again, this should not be an expensive operation, since it is non-blocking.

\section{Research Strategy}
We do not know if and/or to what extent hard fusion will provide any gain over sparse/overlapped tiling strategies. However, there are various hints that suggest so, including the fact that in many problems the amount of data which is indirectly incremented can really be large. Here are a few examples, from finite element:
\begin{itemize}
\item Helmholtz equation, DG tetrahedral elements, polynomial order 2: 100 doubles when iterating over cells (400 over edges)
\item Helmholtz equation, DG tetrahedral elements, polynomial order 3: 400 doubles when iterating over cells (1600 over edges)
\item Elasticity equation, DG tetrahedral elements, polynomial order 2: 900 doubles when iterating over cells (3600 over edges)
\end{itemize}
Note, however, that as the cost of insertion grows, the computational intensity of the kernel increases. So, it's not that simple/nice.

What we could do is the following:
\begin{enumerate}
 \item Real measurement of the insertion cost, i.e. finding the class of problems in which inserting data indirectly in memory represents the dominant cost  (or a significant fraction) of the kernel computation (i.e. kernel is memory bound). This is required to individuate the class of (real) applications motivating the research.
  \newcounter{enumTemp}
 \setcounter{enumTemp}{\theenumi}
 \end{enumerate} 
 Then, show that hard fusion can be more powerful than tiling. This study may even be outside of finite element land (or any other application):
 \begin{enumerate}
  \setcounter{enumi}{\theenumTemp}
 \item We write a simple application in which the loop chain comprises \emph{N} identical loops, iterating (say) over cells, each kernel indirectly incrementing a dataset associated (say) with vertices. Then we 1) sparse/overlapped tile and 2) hard fuse them, and we look at the runtime. Such a kernel would clearly be memory-bound (there's basically no computation at all). Note that here additional gain could come from reduced loop overhead (i.e. the cell loop is iterated only once in the hard fusion case)
  \setcounter{enumTemp}{\theenumi}
 \end{enumerate}
In practice, such a study would still be too simplistic, since in real applications you never have such a straightforward loop chain. Therefore, more realistically, only real experimentation in real code will prove the hyphotesis. If things go bad, i.e. hard fusion is not such a great idea since soft fusion (sparse/overlapped tiling) reaches similar levels of performance, then we need to have a fallback, which could be the following
\begin{enumerate}
  \setcounter{enumi}{\theenumTemp}
\item Overlapped tiling (with MPI support). This has never been studied systematically before. At first glance, overlapped tiling may seem an orthogonal matter w.r.t. to hard fusion, but it is not practically true. If we want to compare hard fusion with tiling in a large number of \textbf{real} finite element codes, we need to integrate inspector/executor systems for both hard fusion and a tiling technique with Firedrake/PyOP2 (the DSLs for solving PDEs at Imperial College). So, eventually, some tiling library needs to be implemented (sparse tiling could be \textit{readapted}, but still it would require some effort). The implementation phase, therefore, could start with an overlapped tiling library. This way, we will probably have in the end a nice story to tell, even though hard fusion is not that great (read: we can get a paper out of it).
\end{enumerate}


\clearpage

\begin{appendices}
\section{Real example}
Here we show example code for two parallel loops automatically generated through Firedrake, representing loop structures 0 and 1 in the first listing of this document.

\scriptsize
\begin{lstlisting}
// Function representing loop structure 0
void wrap_form_interior_facet_integral_0_otherwise(int start, int end, Mat arg0_0_, int *arg0_0_map0_0, int *arg0_0_map1_0, double *arg1_0, int *arg1_0_map0_0, double *arg2_0, int *arg2_0_map0_0, unsigned int *facet_p) 
{
  Mat arg0_0_0 = arg0_0_;
  double *vertex_coordinates[12];
  double *w0[12];
  for ( int n = start; n < end; n++ ) {
    int i = n;
    
    //fetching indirect datasets
    vertex_coordinates[0] = arg1_0 + (arg1_0_map0_0[i * 6 + 0])* 2;
    vertex_coordinates[1] = arg1_0 + (arg1_0_map0_0[i * 6 + 1])* 2;
    vertex_coordinates[2] = arg1_0 + (arg1_0_map0_0[i * 6 + 2])* 2;
    vertex_coordinates[3] = arg1_0 + (arg1_0_map0_0[i * 6 + 3])* 2;
    vertex_coordinates[4] = arg1_0 + (arg1_0_map0_0[i * 6 + 4])* 2;
    vertex_coordinates[5] = arg1_0 + (arg1_0_map0_0[i * 6 + 5])* 2;
    vertex_coordinates[6] = arg1_0 + (arg1_0_map0_0[i * 6 + 0])* 2 + 1;
    vertex_coordinates[7] = arg1_0 + (arg1_0_map0_0[i * 6 + 1])* 2 + 1;
    vertex_coordinates[8] = arg1_0 + (arg1_0_map0_0[i * 6 + 2])* 2 + 1;
    vertex_coordinates[9] = arg1_0 + (arg1_0_map0_0[i * 6 + 3])* 2 + 1;
    vertex_coordinates[10] = arg1_0 + (arg1_0_map0_0[i * 6 + 4])* 2 + 1;
    vertex_coordinates[11] = arg1_0 + (arg1_0_map0_0[i * 6 + 5])* 2 + 1;
    w0[0] = arg2_0 + (arg2_0_map0_0[i * 12 + 0])* 1;
    w0[1] = arg2_0 + (arg2_0_map0_0[i * 12 + 1])* 1;
    w0[2] = arg2_0 + (arg2_0_map0_0[i * 12 + 2])* 1;
    w0[3] = arg2_0 + (arg2_0_map0_0[i * 12 + 3])* 1;
    w0[4] = arg2_0 + (arg2_0_map0_0[i * 12 + 4])* 1;
    w0[5] = arg2_0 + (arg2_0_map0_0[i * 12 + 5])* 1;
    w0[6] = arg2_0 + (arg2_0_map0_0[i * 12 + 6])* 1;
    w0[7] = arg2_0 + (arg2_0_map0_0[i * 12 + 7])* 1;
    w0[8] = arg2_0 + (arg2_0_map0_0[i * 12 + 8])* 1;
    w0[9] = arg2_0 + (arg2_0_map0_0[i * 12 + 9])* 1;
    w0[10] = arg2_0 + (arg2_0_map0_0[i * 12 + 10])* 1;
    w0[11] = arg2_0 + (arg2_0_map0_0[i * 12 + 11])* 1;
    double A[2][2]  = {{0.0}};

    // body of the loop
    unsigned int facet_0 = facet_p[0];
    unsigned int facet_1 = facet_p[1];
    double **vertex_coordinates_0 = vertex_coordinates;
    double **vertex_coordinates_1 = vertex_coordinates + 3;

    double J_0[4];
    compute_jacobian_triangle_int_2d(J_0, vertex_coordinates_0);
    double K_0[4];
    double detJ_0;
    compute_jacobian_inverse_triangle_2d(K_0, detJ_0, J_0);

    double J_1[4];
    compute_jacobian_triangle_int_2d(J_1, vertex_coordinates_1);
    double K_1[4];
    double detJ_1;
    compute_jacobian_inverse_triangle_2d(K_1, detJ_1, J_1);

    // Get vertices on edge
    unsigned int edge_vertices[3][2] = {{1, 2}, {0, 2}, {0, 1}};
    unsigned int v0 = edge_vertices[facet_0][0];
    unsigned int v1 = edge_vertices[facet_0][1];

    // Compute scale factor (length of edge scaled by length of reference interval)
    double dx0 = vertex_coordinates_0[v1+0][0] - vertex_coordinates_0[v0+0][0];
    double dx1 = vertex_coordinates_0[v1+6][0] - vertex_coordinates_0[v0+6][0];
    double det = sqrt(dx0*dx0 + dx1*dx1);

    bool direction = dx1*(vertex_coordinates_0[facet_0][0] - vertex_coordinates_0[v0][0]) - dx0*(vertex_coordinates_0[facet_0 + 6][0] - vertex_coordinates_0[v0 + 6][0]) < 0;
    // Compute facet normals from the facet scale factor constants
    double n_00 = direction ? dx1 / det : -dx1 / det;
    double n_01 = direction ? -dx0 / det : dx0 / det;
    // Compute facet normals from the facet scale factor constants
    double n_10 = !direction ? dx1 / det : -dx1 / det;
    double n_11 = !direction ? -dx0 / det : dx0 / det;
 
    static const double W1  = 1.0;  
    static const double FE0_f0_C1[1][6]  = {{-0.5, 1.0, 0.5, -1.0, 0.5, -1.0}};  
    static const double FE0_f0_C0[1][6]  = {{1.0, -0.5, -0.5, 1.0, -0.5, 1.0}};  
    static const double FE0_f2_C1[1][6]  = {{0.0, 0.0, 0.0, 0.0, -0.5, -0.5}};  
    static const double FE0_f2_C0[1][6]  = {{1.0, -0.5, 1.0, -0.5, -0.5, 1.0}};  
    static const double FE1_f0[1][1]  = {{1.0}};  
    static const double FE0_f1_C0[1][6]  = {{0.0, 0.0, 0.5, 0.5, 0.0, 0.0}};  
    static const double FE0_f1_C1[1][6]  = {{-0.5, 1.0, 0.5, -1.0, -1.0, 0.5}};

    double F0  = 0.0;
    double F1  = 0.0;
    double F2  = 0.0;
    double F3  = 0.0;

    for (int r  = 0; r < 6; ++r)
    {
      F0 += (w0[r + 6][0] * FE0_f0_C0[0][r]);
      F1 += (w0[r + 6][0] * FE0_f0_C1[0][r]);
      F2 += (w0[r][0] * FE0_f0_C0[0][r]);
      F3 += (w0[r][0] * FE0_f0_C1[0][r]);      
    }
    for (int j  = 0; j < 1; ++j)
    {
      for (int k  = 0; k < 1; ++k)
      {
        A[j][(k + 1)] += ((((((1.0 / detJ_1) * J_1[3] * F1) + ((1.0 / detJ_1) * J_1[2] * F0)) * n_11) + ((((1.0 / detJ_1) * J_1[1] * F1) + ((1.0 / detJ_1) * J_1[0] * F0)) * n_10) + fabs((n_10*(F0*J_1[0]*1.0/detJ_1 + F1*J_1[1]*1.0/detJ_1) + n_11*(F0*J_1[2]*1.0/detJ_1 + F1*J_1[3]*1.0/detJ_1)))) * det * W1 * FE1_f0[0][k] * FE1_f0[0][j] * -0.5);
        A[j][k] += ((((((1.0 / detJ_0) * J_0[3] * F3) + ((1.0 / detJ_0) * J_0[2] * F2)) * n_01) + ((((1.0 / detJ_0) * J_0[1] * F3) + ((1.0 / detJ_0) * J_0[0] * F2)) * n_00) + fabs((n_00*(F2*J_0[0]*1.0/detJ_0 + F3*J_0[1]*1.0/detJ_0) + n_01*(F2*J_0[2]*1.0/detJ_0 + F3*J_0[3]*1.0/detJ_0)))) * det * W1 * FE1_f0[0][k] * FE1_f0[0][j] * 0.5);
        A[(j + 1)][k] += ((((((1.0 / detJ_0) * J_0[3] * F3) + ((1.0 / detJ_0) * J_0[2] * F2)) * n_01) + ((((1.0 / detJ_0) * J_0[1] * F3) + ((1.0 / detJ_0) * J_0[0] * F2)) * n_00) + fabs((n_00*(F2*J_0[0]*1.0/detJ_0 + F3*J_0[1]*1.0/detJ_0) + n_01*(F2*J_0[2]*1.0/detJ_0 + F3*J_0[3]*1.0/detJ_0)))) * det * W1 * FE1_f0[0][k] * FE1_f0[0][j] * -0.5);
        A[(j + 1)][(k + 1)] += ((((((1.0 / detJ_1) * J_1[3] * F1) + ((1.0 / detJ_1) * J_1[2] * F0)) * n_11) + ((((1.0 / detJ_1) * J_1[1] * F1) + ((1.0 / detJ_1) * J_1[0] * F0)) * n_10) + fabs((n_10*(F0*J_1[0]*1.0/detJ_1 + F1*J_1[1]*1.0/detJ_1) + n_11*(F0*J_1[2]*1.0/detJ_1 + F1*J_1[3]*1.0/detJ_1)))) * det * W1 * FE1_f0[0][k] * FE1_f0[0][j] * 0.5);        
      }      
    }
    // omitting other stuff
    ...
    
    //matrix insertion
    insert(arg0_0_0, A, 2, arg0_0_map0_0 + i * 2, 2, arg0_0_map1_0 + i * 2, 0);
  }
}


// Function representing loop structure 1
void wrap_form_cell_integral_0_otherwise(int start, int end, Mat arg0_0_, int *arg0_0_map0_0, int *arg0_0_map1_0, double *arg1_0, int *arg1_0_map0_0, double *arg2_0, int *arg2_0_map0_0) 
{
  Mat arg0_0_0 = arg0_0_;
  double *vertex_coordinates[6];
  double *w0[6];
  for ( int n = start; n < end; n++ ) {
    int i = n;
    
    //fetching indirect datasets
    vertex_coordinates[0] = arg1_0 + (arg1_0_map0_0[i * 3 + 0])* 2;
    vertex_coordinates[1] = arg1_0 + (arg1_0_map0_0[i * 3 + 1])* 2;
    vertex_coordinates[2] = arg1_0 + (arg1_0_map0_0[i * 3 + 2])* 2;
    vertex_coordinates[3] = arg1_0 + (arg1_0_map0_0[i * 3 + 0])* 2 + 1;
    vertex_coordinates[4] = arg1_0 + (arg1_0_map0_0[i * 3 + 1])* 2 + 1;
    vertex_coordinates[5] = arg1_0 + (arg1_0_map0_0[i * 3 + 2])* 2 + 1;
    w0[0] = arg2_0 + (arg2_0_map0_0[i * 6 + 0])* 1;
    w0[1] = arg2_0 + (arg2_0_map0_0[i * 6 + 1])* 1;
    w0[2] = arg2_0 + (arg2_0_map0_0[i * 6 + 2])* 1;
    w0[3] = arg2_0 + (arg2_0_map0_0[i * 6 + 3])* 1;
    w0[4] = arg2_0 + (arg2_0_map0_0[i * 6 + 4])* 1;
    w0[5] = arg2_0 + (arg2_0_map0_0[i * 6 + 5])* 1;
    double A[1][1]  = {{0.0}};

    // body of the loop
    double J[4];
    compute_jacobian_triangle_2d(J, vertex_coordinates);
    double K[4];
    double detJ;
    compute_jacobian_inverse_triangle_2d(K, detJ, J);  
    const double det = fabs(detJ);

    static const double W1  = 0.5;  
    static const double FE1_D01[1][1]  = {{0.0}};  
    static const double FE1[1][1]  = {{1.0}};  
    static const double FE0_C1[1][6]  = {{...}};  
    static const double FE0_C0[1][6]  = {{...}};

    double F0  = 0.0;
    double F1  = 0.0;

    for (int r  = 0; r < 6; ++r)
    {
      F0 += (w0[r][0] * FE0_C0[0][r]);
      F1 += (w0[r][0] * FE0_C1[0][r]);  
    }

    for (int j  = 0; j < 1; ++j)
      for (int k  = 0; k < 1; ++k)
        A[j][k] += (((((K[3] * FE1_D01[0][j]) + (K[1] * FE1_D01[0][j])) * (((1.0 / detJ) * J[3] * F1) + ((1.0 / detJ) * J[2] * F0))) + (((K[2] * FE1_D01[0][j]) + (K[0] * FE1_D01[0][j])) * (((1.0 / detJ) * J[1] * F1) + ((1.0 / detJ) * J[0] * F0)))) * det * W1 * FE1[0][k] * -1.0);      
   
   // matrix insertion (call to PETSC  
    insert(arg0_0_0, A, 1, arg0_0_map0_0 + i * 1, 1, arg0_0_map1_0 + i * 1, 0);
  }
}
\end{lstlisting}

\end{appendices}



%\begin{thebibliography}{99}
%\setlength{\parskip}{0pt}
%
%\bibitem{FFC-Compiler} Robert~C. Kirby and Anders Logg. 
%\newblock A compiler for variational forms.
%\newblock {\em ACM Trans. Math. Softw.}, 32(3):417--444, September 2006.
%
%\end{thebibliography}



\end{document}
